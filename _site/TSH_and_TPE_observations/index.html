<!DOCTYPE html>
<html>
  <head>
    <title>"Testing Statistical Hypotheses" and "Theory of Point Estimation" impressions – Alexej Gossmann – I am interested in math, stats, coding, genetics, ...</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
" />
    <meta property="og:description" content="
" />
    
    <meta name="author" content="Alexej Gossmann" />

    
    <meta property="og:title" content=""Testing Statistical Hypotheses" and "Theory of Point Estimation" impressions" />
    <meta property="twitter:title" content=""Testing Statistical Hypotheses" and "Theory of Point Estimation" impressions" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Alexej Gossmann - I am interested in math, stats, coding, genetics, ..." href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
 
    <!-- MathJax interation-->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [["$","$"]]}});
      MathJax.Hub.Config({TeX: {Macros:{subscript:['_{#1}',1],superscript:['^{#1}',1]}}});
    </script> 
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full">
    </script>
 </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://avatars0.githubusercontent.com/u/11449372?v=3&s=460" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Alexej Gossmann</a></h1>
            <p class="site-description">I am interested in math, stats, coding, genetics, ...</p>
          </div>

          <nav>
            <a href="/about">About</a>
            <a href="/">Blog</a>
            <a href="/talks">Presentations</a>
            <a href="/publications">Publications</a>
            <a href="/software">Software</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>"Testing Statistical Hypotheses" and "Theory of Point Estimation" impressions</h1>

  <div class="entry">
    <script type="text/javascript">
function toggleMe(a){
var e=document.getElementById(a);
if(!e)return true;
if(e.style.display=="none"){
e.style.display="block"
}
else{
e.style.display="none"
}
return true;
}
</script>

<p>I am currently reading Lehmann &amp; Romano &quot;Testing Statistical Hypotheses&quot; (3rd ed.) and Lehmann &amp; Casella &quot;Theory of Point Estimation&quot; (2nd ed.), abbr. TSH and TPE. The following is a collection of <del>random facts</del> observations I made while reading TSH and TPE.</p>

<p><img class='emoji' title=':construction_worker:' alt=':construction_worker:' src='https://assets.github.com/images/icons/emoji/unicode/1f477.png' height='20' width='20' align='absmiddle' /> <em>This post will be regularly updated.</em> <img class='emoji' title=':construction_worker:' alt=':construction_worker:' src='https://assets.github.com/images/icons/emoji/unicode/1f477.png' height='20' width='20' align='absmiddle' /></p>

<p><strong>Clickable items:</strong></p>

<!-- 
* some things that were not clear to me before, 
* some results I found interesting, 
* definitions that are better than their equivalents that I have seen before,
* and other observations I made while reading TSH and TPE.

Brainstorming:

* LME = posterior mode with a uniform prior; LASSO estimate = posterior mode with a Laplacian prior
* definition of unbiased
* two-sided hypotheses tests: exerises 3.54 and 3.2 (ii)
* fundamental Neyman-Pearson lemma and generalizations
* relationship tests x CI

-->

<p><br>
<input type="button" onclick="return toggleMe('unbiased')" value="+ Topic:"> <b>On the notion of unbiasedness of estimators, hypotheses tests, and confidence intervals</b><br>
<div id="unbiased" style="display:none"></p>

<h2>On the notion of unbiasedness of estimators, hypotheses tests, and confidence intervals</h2>

<p>The following discusses various well-known definitions of unbiasedness, their generalizations and relationships with each other, as well as some of the underlying intuition (such as the relationship between hypotheses tests and confidence intervals).</p>

<h3>Unbiased estimators</h3>

<p>The well-known and widely used definition of an unbiased estimator $\hat{\theta}$ of a parameter $\theta$ is</p>

<p>$$\mathrm{E}\subscript{\theta}(\hat{\theta}) = \theta.$$</p>

<p>However it can be generalized as follows. Assume that there is a loss function $L(\theta, \hat{\theta})$, which only depends on the correct parameter $\theta$ and the estimate $\hat{\theta}$ (i.e. it measures how far off the estimator is from the parameter that it aims to estimate).
Then $\hat{\theta}$ is said to be unbiased for $\theta$ with respect to $L$, if for all $\theta^\prime$ it holds that</p>

<p>$$\mathrm{E}\subscript{\theta}(L(\theta^\prime, \hat{\theta})) \geq \mathrm{E}\subscript{\theta}(L(\theta, \hat{\theta})).$$</p>

<p>That is, if $\hat{\theta}$ is on average closer to the correct parameter $\theta$ than to any wrong parameter $\theta^\prime$ in the parameter space.</p>

<p>When estimating a real valued $\theta$ with the square of the error as loss, the above condition becomes</p>

<p>$$\mathrm{E}\subscript{\theta}\left(\left| \theta^\prime - \hat{\theta} \right|^2\right) \geq \mathrm{E}\subscript{\theta}\left(\left| \theta - \hat{\theta}\right|^2\right).$$</p>

<p>If $\mathrm{E}\subscript{\theta}\hat{\theta}$ is one of the possible values of $\theta$, then by adding and subtracting $\mathrm{E}\subscript{\theta}\hat{\theta}$ inside the parentheses on both sides of the equation it follows that the above unbiasedness condition is satisfied if and only if</p>

<p>$$\mathrm{E}\subscript{\theta}(\hat{\theta}) = \theta.$$</p>

<p>This equivalence also holds under somewhat more general assumptions, see exercise 1.2 in TSH.</p>

<h3>Unbiased tests</h3>

<p>Consider a level $\alpha$ test $\phi$ of the hypothesis $H : \theta \in \Omega\subscript{H}$ against an alternative $K : \theta \in \Omega\subscript{K}$.
Denote the power function of $\phi$ by $\beta\subscript{\phi}(\theta) = \mathrm{E}\subscript{\theta} \phi(X)$.
Then it is natural to define unbiasedness of $\phi$ by the criterion</p>

<p>$$
\begin{eqnarray}
\beta\subscript{\phi}(\theta) &amp;\leq&amp; \alpha \quad \mathrm{if}\, H : \theta \in \Omega\subscript{H}, \\\
\beta\subscript{\phi}(\theta) &amp;\geq&amp; \alpha \quad \mathrm{if}\,  K : \theta \in \Omega\subscript{K}. 
\end{eqnarray}
$$</p>

<p>In particular, it follows that $\beta\subscript{\phi}(\theta) = \alpha$ on the common boundary of $\Omega\subscript{H}$ and $\Omega\subscript{K}$. In fact, a test that is the most powerful among all such tests, is UMP unbiased (Lemma 4.1.1 in TSH). </p>

<p>However, the definition of an unbiased test can be generalized in the same way as that of an unbiased estimator shown above.
Assume that there is a loss function $L(\theta, \phi(x))$, which only depends on the true value of $\theta$ and the decision $\phi(x)$ takes by the test $\phi$. Then the hypothesis test is unbiased with respect to $L$, if for all $\theta^\prime$ it holds that</p>

<p>$$\mathrm{E}\subscript{\theta}(L(\theta^\prime, \phi(X))) \geq \mathrm{E}\subscript{\theta}(L(\theta, \phi(X))).$$</p>

<p>For the test $\phi$ of $H$ vs. $K$ let the loss function be equal to $\alpha$ if a Type II error is committed and equal $(1-\alpha)$ if a Type I error is committed. Then </p>

<p>$$
\mathrm{E}\subscript{\theta}(L(\theta^\prime, \phi(X))) = 
\begin{cases}
\alpha (1 - \beta\subscript{\phi}(\theta)) \quad &amp;\mathrm{if}&amp;\, \theta^\prime \in \Omega\subscript{K}\\\ 
(1-\alpha) \beta\subscript{\phi}(\theta) \quad &amp;\mathrm{if}&amp;\, \theta^\prime \in \Omega\subscript{H},
\end{cases}
$$</p>

<p>It follows that if $\theta \in \Omega\subscript{H}$ then $\alpha (1 - \beta\subscript{\phi}(\theta)) \geq (1-\alpha) \beta\subscript{\phi}(\theta)$, and consequently</p>

<p>$$\beta\subscript{\phi}(\theta) \leq \alpha.$$</p>

<p>Similarly, by considering $\theta\in\Omega\subscript{K}$, we get $\beta\subscript{\phi}(\theta) \geq \alpha$. Thus the usual definition is a special case of the more general loss-function-based definition.</p>

<h3>Unbiased confidence sets</h3>

<p>As is well-known, the defining condition for a confidence interval $\left(\underline{\theta}, \overline{\theta}\right)$ is</p>

<p>$$P\subscript{\theta}\left(\underline{\theta}(X) \leq \theta \leq \overline{\theta}(X)\right) \geq 1-\alpha,$$</p>

<p>for all $\theta$.</p>

<h4>Hypotheses tests vs. confidence intervals</h4>

<p>It is well-known that hypotheses tests and confidence intervals generally do exactly the same thing.
However, to describe with mathematical rigour in what sense it is true requires a little thinking.</p>

<p>Consider a level $\alpha$ test of a two-sided hypothesis test $H : \theta = \theta\subscript{0}$ vs. $K : \theta \neq \theta\subscript{0}$, and denote its acceptance region by $A(\theta\subscript{0})$.
Define the inclusion region of the confidence set to be</p>

<p>$$S(x) := \{ \theta : x\in A(\theta) \},$$</p>

<p>that is, $\theta \in S(x)$ if and only if $x\in A(\theta)$. Then $S(x)$ defines a $(1-\alpha) \cdot 100\%$ confidence set, because for all $\theta$ we have</p>

<p>$$P\subscript{\theta}(\theta \in S(x)) = P\subscript{\theta}(x\in A(\theta)) \geq 1 - \alpha.$$</p>

<p>Conversely, if we start out with a family of confidence sets $\{S(x) : x\in\mathcal{X}\}$, and define $A(\theta) := \{x : \theta\in S(x)\}$, then for any $\theta$ it holds that</p>

<p>$$P\subscript{\theta}(x\in A(\theta)) = P\subscript{\theta}(\theta \in S(x)) \geq 1 - \alpha.$$</p>

<p>It follows that $P\subscript{\theta}(\mathrm{Type\,I\,error}) \leq \alpha$, that is, $A(\theta)$ is the acceptance region of a level $\alpha$ test.</p>

<h4>Unbiased confidence sets</h4>

<p>Now it suggests itself to define an unbiased confidence set as one that stems from an unbiased hypothesis test by the above procedure. 
In the two-sided case discussed above this condition reduces to</p>

<p>$$P\subscript{\theta}\left(\underline{\theta}(x) \leq \theta^\prime \leq \overline{\theta}(x)\right) \leq 1 - \alpha$$</p>

<p>for all $\theta^\prime$ and $\theta$ such that $\theta \neq \theta^\prime$. That is, the inclusion probability of the null hypothesis parameter $\theta^\prime$ in the confidence interval, when the alternative $\theta$ is true, is less than the confidence level.</p>

<p>Similarly, uniformly most accurate confidence intervals correspond to uniformly most powerful tests (see section 3.5 in TSH for more detail).
However, UMP tests usually do not exist, which is a reason to concentrate on unbiasedness instead. In particular, UMP unbiased tests correspond to uniformly most accurate unbiased confidence sets, i.e.  $S(x)$ such that for all $\theta^\prime$ and $\theta$ with $\theta\in K(\theta^\prime)$ the probability $P\subscript{\theta}(\theta^\prime\in S(x))$ is minimized.
</div></p>

<p><br>
<input type="button" onclick="return toggleMe('para2')" value="+ Topic:"> <b>Conditional expectation, conditional distribution, sufficiency, decision procedures</b><br>
<div id="para2" style="display:none"></p>

<h2>Conditional expectation, conditional distribution, sufficiency, decision procedures</h2>

<p>Consider a random variable $X$ with sample space $(\mathcal{X}, \mathcal{A})$ and probability distribution $P^X$, and a statistic $T(X)$ with range space $(\mathcal{T}, \mathcal{B})$.</p>

<h4>Definition [$\mathrm{E}(f(X)|t)$]</h4>

<p><em>Let $f(x)$ be a non-negative, $\mathcal{A}$-measurable and $P^X$-integrable function.
A $\mathcal{B}$-measurable function $g(t)$ is the conditional expectation of $X$ for given $t$, i.e. $\mathrm{E}(f(X)|t) = \mathrm{E}(f(X)|T=t) = g(t)$, if for all sets $B\in\mathcal{B}$ it holds that</em></p>

<p>$$\int\subscript{T^{-1}(B)} f(x) dP^X(x) = \int\subscript{B} g(t) dP^T(t).$$</p>

<p>Some observations regarding this definition:</p>

<ul>
<li><p>In fact, if we define $f\subscript{0}(x) = g(T(x))$, then by Lemma 2.3.2 in TSH the above formula becomes</p>

<p>$$\int\subscript{A} f(x) dP^X(x) = \int\subscript{A} f\subscript{0}(x) dP^X(x), \forall A \in \mathcal{A}\subscript{0},$$</p>

<p>where $\mathcal{A}\subscript{0}$ is the $\sigma$-algebra induced by $T$.</p></li>
<li><p>The existence and uniqueness $(\mathcal{A}\subscript{0}, P^X)$ of such a function $f\subscript{0}$ follows from Radon-Nikodym Theorem.</p></li>
<li><p>If $f$ is not non-negative, then we can use the usual decomposition $f = f^+ - f^-$ and define</p>

<p>$$\mathrm{E}(f(X)|t) = \mathrm{E}(f^+(X)|t) - \mathrm{E}(f^-(X)|t).$$</p></li>
</ul>

<h4>Definition [$P(A|t)$]</h4>

<p><em>Let $I\subscript{A}(X)$ be a random variable that is equal to one if and only if $X\in A$. The conditional probability of $A$ given $T=t$ can be defined as</em></p>

<p>$$P(A|t) = E(I\subscript{A}(X) | t).$$</p>

<p>This definition seems natural, and in fact, if $T$ has Euclidean domain and range spaces or if $\mathrm{E}|f(X)| &lt; \infty$, then the above defines the <em>conditional probability distribution</em> $P^{X|t}$ (see Theorems 2.5.2 and 2.5.3 in TSH).</p>

<h4>Definition [Sufficiency]</h4>

<p><em>Let $\mathcal{P} = \{P\subscript{\theta} : \theta\in\Omega\}$ be a family of distributions over a sample space $(\mathcal{X}, \mathcal{A})$.</em>
<em>$T$ is sufficient for $\mathcal{P}$ (or $\theta$) if $P\subscript{\theta}(A|t)$ is independent of $\theta$ for every $A\in\mathcal{A}$.</em></p>

<p>In particular, the class of decision procedures depending on a sufficient statistic $T$ is <em>essentially complete</em>. To see this, assume that the sample space is Euclidean, then by Theorem 2.5.1 in TSH there exists the conditional probability distribution $P^{X|t}$. Let $\phi(x)$ be a decision procedure. Given only the value of the sufficient statistic $T(X)$ (but not $X$), define another decision procedure $\psi(t)$ as a random sample from the distribution $P^{X|t}$. Then $\phi(X)$ and $\psi(T)$ have identical distributions. Consequently, both decision procedures have the same risk,</p>

<p>$$R(\theta, \psi) = \mathrm{E}(L(\theta, \psi(T))) = \mathrm{E}(L(\theta, \phi(X))) = R(\theta, \phi).$$</p>

<p>Thus, for any decision procedure that is based on $X$, there is a decision procedure based on $T$ that is equally good or better.</p>

<p>For a proof in the general (non-Euclidean) case see exercise 2.13 in TSH.</p>

<h3>General conditional expectation</h3>

<p>Let $X$ and $Y$ be two real-valued random variables, which can be written as mappings $X: \Omega \to \mathbb{R}$ and $Y: \Omega \to \mathbb{R}$ over a measurable space $(\Omega, \mathcal{A}, P)$. The above definition of $\mathrm{E}(X|T(X)=t)$ suggests a similar definition of $\mathrm{E}(X|Y=y)$. Namely, $\mathrm{E}(X|Y=y) = g(y)$ if for all Borel sets $A$ it holds that</p>

<p>$$\int\subscript{Y^{-1}(A)} X(\omega) dP(\omega) = \int\subscript{A} g(y) dP^Y(y).$$</p>

<p>In fact, a more general version of this definition is given in Feller&#39;s &quot;An Introduction to Probability Theory and its Applications. Volume II&quot; (10.6) as,</p>

<p>$$\mathrm{E}(X\cdot I\subscript{A}(Y)) = \int\subscript{A} \mathrm{E}(X | y) \mu\{dy\},$$</p>

<p>for any pair of random variables $X$ and $Y$.</p>

<p>If $X$ and $Y$ are real-valued one-dimensional, then the pair $(X,Y)$ can be viewed as a random vector in the plane. Each set $\{Y \in A\}$ consists of parallels to the $x$-axis, and we can define a $\sigma$-algebra induced by $Y$ as the collection of all sets $\{Y \in A\}$, where $A$ are Borel sets. Then $\mathrm{E}(X|Y)$ is a random variable, such that $\mathrm{E}(X\cdot I\subscript{B}) = \mathrm{E}(\mathrm{E}(X|Y) \cdot I\subscript{B})$ for all $B=\{Y\in A\}$ with $A$ being a Borel set. This leads to the following general definition.</p>

<h4>Definition [Conditional expectation]</h4>

<p><em>Let $\mathcal{A}$ be the underlying $\sigma$-algebra of sets, and let $\mathcal{B}$ be a $\sigma$-algebra contained in $\mathcal{A}$. Let $X$ be a random variable.</em></p>

<ol>
<li><p><em>A random variable $U$ is called a conditional expectation of $X$ relative to $\mathcal{B}$ (or $U=\mathrm{E}(X|\mathcal{B})$), if it is $\mathcal{B}$-measurable and for all $B\in\mathcal{B}$ it holds that</em></p>

<p>$$\mathrm{E}(X\cdot I\subscript{B}) = \mathrm{E}(U \cdot I\subscript{B}).$$</p></li>
<li><p><em>If $\mathcal{B}$ is the $\sigma$-algebra generated by a random variable $Y$, then $\mathrm{E}(X|Y) = \mathrm{E}(X|\mathcal{B})$.</em></p></li>
</ol>

<p></div></p>

  </div>

  <div class="date">
    Written on October 29, 2015
  </div>

  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'agisga';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          



<a href="http://github.com/agisga"><i class="svg-icon github"></i></a>

<a href="http://linkedin.com/in/alexejgossmann"><i class="svg-icon linkedin"></i></a>


<a href="http://twitter.com/agisga"><i class="svg-icon twitter"></i></a>


        </footer>
      </div>
    </div>

    

  </body>
</html>
