<!DOCTYPE html>
<html>
  <head>
    <title>Statistical linear mixed models in Ruby with mixed_models (GSoC2015) – Alexej Gossmann – Math PhD student at Tulane University</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Google Summer of Code 2015 is coming to an end. During this summer, I have learned too many things to list here about statistical modeling, Ruby and software development in general, and I had a lot of fun in the process!

" />
    <meta property="og:description" content="Google Summer of Code 2015 is coming to an end. During this summer, I have learned too many things to list here about statistical modeling, Ruby and software development in general, and I had a lot of fun in the process!

" />
    
    <meta name="author" content="Alexej Gossmann" />

    
    <meta property="og:title" content="Statistical linear mixed models in Ruby with mixed_models (GSoC2015)" />
    <meta property="twitter:title" content="Statistical linear mixed models in Ruby with mixed_models (GSoC2015)" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Alexej Gossmann - Math PhD student at Tulane University" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
 
    <!-- MathJax interation-->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [["$","$"]]}});
      MathJax.Hub.Config({TeX: {Macros:{subscript:['_{#1}',1],superscript:['^{#1}',1]}}});
    </script> 
    <!-- Turn on equation numbering -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
    </script>
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full">
    </script>
 </head>

  <body>
    <div class="wrapper-masthead">
      <header class="masthead clearfix">
        <a href="/" class="site-avatar"><img src="https://avatars0.githubusercontent.com/u/11449372?v=3&s=460" /></a>

        <div class="site-info">
          <h1 class="site-name"><a href="/">Alexej Gossmann</a></h1>
          <p class="site-description">Math PhD student at Tulane University</p>
        </div>

        <nav>
          <a href="/about" class="blue">About</a>
          <a href="/" class="yellow">Blog</a>
          <a href="/talks" class="green">Presentations</a>
          <a href="/publications" class="magenta">Publications</a>
          <a href="/software" class="cyan">Software</a>
        </nav>
      </header>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Statistical linear mixed models in Ruby with mixed_models (GSoC2015)</h1>

  <div class="entry">
    <p>Google Summer of Code 2015 is coming to an end. During this summer, I have learned too many things to list here about statistical modeling, Ruby and software development in general, and I had a lot of fun in the process!</p>

<h2 id="linear-mixed-models">Linear mixed models</h2>

<p>My GSoC project is the Ruby gem <a href="https://github.com/agisga/mixed_models">mixed_models</a>. Mixed models are statistical models which predict the value of a response variable as a result of fixed and random effects. The gem in its current version can be used to fit statistical linear mixed models and perform statistical inference on the model parameters as well as to predict future observations. A number of tutorials/examples in IRuby notebook format are accessible from the <code class="highlighter-rouge">mixed_models</code> <a href="https://github.com/agisga/mixed_models">github repository</a>.</p>

<p>Linear mixed models are implemented in the class <code class="highlighter-rouge">LMM</code>. The constructor method <code class="highlighter-rouge">LMM#initialize</code> provides a flexible model specification interface, where an arbitrary covariance structure of the random effects terms can be passed as a <code class="highlighter-rouge">Proc</code> or a block.</p>

<p>A convenient user-friendly interface to the basic model fitting algorithm is <code class="highlighter-rouge">LMM#from_formula</code>, which uses the formula language of the R mixed models package <code class="highlighter-rouge">lme4</code> for model specification. With the <code class="highlighter-rouge">#from_formula</code> method, the user can conveniently fit models with categorical predictor variables, interaction fixed or random effects, as well as multiple crossed or nested random effects, all with just one line of code.</p>

<p>Examples are given in the sections below.</p>

<h3 id="implementation">Implementation</h3>

<p>The parameter estimation in <code class="highlighter-rouge">LMM#initialize</code> is largely based on the approach developed by the authors of the R mixed models package <code class="highlighter-rouge">lme4</code>, which is delineated in the <code class="highlighter-rouge">lme4</code> <a href="https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf">vignette</a>. I have tried to make the code of the model fitting algorithm in <code class="highlighter-rouge">LMM#initialize</code> easy to read, especially compared to the corresponding implementation in <code class="highlighter-rouge">lme4</code>.</p>

<p>The <code class="highlighter-rouge">lme4</code> code is largely written in C++, which is integrated in R via the packages <code class="highlighter-rouge">Rcpp</code> and <code class="highlighter-rouge">RcppEigen</code>. It uses <a href="https://developer.nvidia.com/cholmod">CHOLMOD</a> code for various sparse matrix tricks, and it involves passing pointers to C++ object to R (and vice versa) many times, and passing different R environments from function to function. All this makes the <code class="highlighter-rouge">lme4</code> code rather hard to read. Even Douglas Bates, the main developer of <code class="highlighter-rouge">lme4</code>, admits that <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022791.html">“The end result is confusing (my fault entirely) and fragile”</a>, because of all the utilized performance improvements. I have analyzed the <code class="highlighter-rouge">lme4</code> code in three blog posts (<a href="http://agisga.github.io/Dissect_lmer_part1/">part 1</a>, <a href="http://agisga.github.io/Dissect_lmer_part2/">part 2</a> and <a href="http://agisga.github.io/Dissect_lmer_part3/">part 3</a>) before starting to work on my gem <code class="highlighter-rouge">mixed_models</code>.</p>

<p>The method <code class="highlighter-rouge">LMM#initialize</code> is written in a more functional style, which makes the code shorter and (I find) easier to follow.  All matrix calculations are performed using the gem <a href="https://github.com/SciRuby/nmatrix"><code class="highlighter-rouge">nmatrix</code></a>, which has a quite intuitive syntax and contributes to the overall code readability as well. The Ruby gem loses with respect to memory consumption and speed in comparison to <code class="highlighter-rouge">lme4</code>, because it is written in pure Ruby and does not utilize any sparse matrix tricks. However, for the same reasons the <code class="highlighter-rouge">mixed_models</code> code is much shorter and easier to read than <code class="highlighter-rouge">lme4</code>. Moreover, the linear mixed model formulation in <code class="highlighter-rouge">mixed_models</code> is a little bit more general, because it does not assume that the random effects covariance matrix is sparse. More about the implementation of <code class="highlighter-rouge">LMM#initialize</code> can be found in <a href="http://agisga.github.io/First-linear-mixed-model-fit/">this blog post</a>.</p>

<h3 id="other-existing-tools">Other existing tools</h3>

<p>Popular existing software packages for mixed models include the R package <a href="https://cran.r-project.org/web/packages/lme4/index.html"><code class="highlighter-rouge">lme4</code></a> (which is arguably the standard software for linear mixed models), the R package <a href="https://cran.r-project.org/web/packages/nlme/index.html"><code class="highlighter-rouge">nlme</code></a> (an older package developed by the same author as <code class="highlighter-rouge">lme4</code>, still widely used), Python’s <a href="https://github.com/statsmodels/statsmodels/blob/master/statsmodels/regression/mixed_linear_model.py"><code class="highlighter-rouge">statmodels</code></a>, and the Julia package <a href="https://github.com/dmbates/MixedModels.jl"><code class="highlighter-rouge">MixedModels.jl</code></a>.</p>

<p>Below, I give a couple of examples illustrating some of the capabilities of <code class="highlighter-rouge">mixed_models</code> and explore how it compares to the alternatives.</p>

<h3 id="a-usage-example-and-discussion">A usage example and discussion</h3>

<p>As an example, we use <a href="http://archive.ics.uci.edu/ml/datasets/BlogFeedback">data</a> from the UCI machine learning repository, which originate from blog posts from various sources in 2010-2012, in order to model (the logarithm of) the number of comments that a blog post receives. The linear predictors are the text length, the log-transform of the average number of comments at the hosting website, the average number of trackbacks at the hosting website, and the parent blog posts. We assume a random effect on the number of comments due to the day of the week on which the blog post was published. In <code class="highlighter-rouge">mixed_models</code> this model can be fit with</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">model_fit</span> <span class="o">=</span> <span class="no">LMM</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="ss">formula: </span><span class="s2">"log_comments ~ log_host_comments_avg + host_trackbacks_avg + length + has_parent_with_comments + (1 | day)"</span><span class="p">,</span> 
                              <span class="ss">data: </span><span class="n">blog_data</span><span class="p">)</span>
</code></pre>
</div>

<p>and we can display some information about the estimated fixed effects with</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="nb">puts</span> <span class="n">model_fit</span><span class="p">.</span><span class="nf">fix_ef_summary</span><span class="p">.</span><span class="nf">inspect</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>
</code></pre>
</div>

<p>which produces the following output:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>                                             coef                       sd                  z_score            WaldZ_p_value 
               intercept       1.2847896684307731     0.030380582281933178        42.28983027737477                      0.0 
   log_host_comments_avg        0.415586319225577     0.007848368759350875        52.95193586953086                      0.0 
     host_trackbacks_avg     -0.07551588997745964     0.010915623834434068       -6.918146971979714    4.575895218295045e-12 
                  length   1.8245853808280765e-05    2.981631039432429e-06        6.119420400102211    9.391631916599863e-10 
has_parent_with_comments      -0.4616662830553772      0.13936886611993773      -3.3125496095955715    0.0009244972814528296 
</code></pre>
</div>

<p>We can also display the estimated random effects coefficients and the random effects standard deviation,</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="nb">puts</span> <span class="s2">"Random effects coefficients:"</span>
<span class="nb">puts</span> <span class="n">model_fit</span><span class="p">.</span><span class="nf">ran_ef</span>
<span class="nb">puts</span> <span class="s2">"Random effects correlation structure:"</span>
<span class="nb">puts</span> <span class="n">model_fit</span><span class="p">.</span><span class="nf">ran_ef_summary</span><span class="p">.</span><span class="nf">inspect</span>
</code></pre>
</div>

<p>which produces</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Random effects coefficients:
{:intercept_fr=&gt;0.0, :intercept_mo=&gt;0.0, :intercept_sa=&gt;0.0, :intercept_su=&gt;0.0, :intercept_th=&gt;0.0, :intercept_tu=&gt;0.0, :intercept_we=&gt;0.0}
Random effects standard deviation:

#&lt;Daru::DataFrame:70278348234580 @name = 8e11a27f-81b0-48a0-9771-085a8f30693d @size = 1&gt;
                  day 
       day        0.0 
</code></pre>
</div>

<p>Interestingly, the estimates of the random effects coefficients and standard deviation are all zero! That is, we have a singular fit. Thus, our results imply that the day of the week on which a blog post is published has no effect on the number of comments that the blog post will receive.</p>

<p>It is worth pointing out that such a model fit with a singular covariance matrix is problematic with the current version of Python’s <code class="highlighter-rouge">statmodels</code> (described as “numerically challenging” in the <a href="http://statsmodels.sourceforge.net/devel/mixed_linear.html">documentation</a>) and the R package <code class="highlighter-rouge">nlme</code> (“Singular covariance matrices correspond to infinite parameter values”, a <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022791.html">mailing list reply</a> by Douglas Bates, the author of <code class="highlighter-rouge">nlme</code>). However, <code class="highlighter-rouge">mixed_models</code>, <code class="highlighter-rouge">lme4</code> and <code class="highlighter-rouge">MixedModels.jl</code> can handle singular fits without problems. In fact, like <code class="highlighter-rouge">mixed_models</code> above, <code class="highlighter-rouge">lme4</code> estimates the random effects coefficients and standard deviation to be zero, as we can see from the following R output:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;</span> <span class="n">mod</span> <span class="o">&lt;-</span> <span class="n">lmer</span><span class="p">(</span><span class="n">log_comments</span> <span class="o">~</span> <span class="n">log_host_comments_avg</span> <span class="o">+</span> <span class="n">host_trackbacks_avg</span> <span class="o">+</span> <span class="n">length</span> <span class="o">+</span> <span class="n">has_parent_with_comments</span> <span class="o">+</span> <span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">day</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span>
<span class="n">Warning</span> <span class="n">message</span><span class="o">:</span>
<span class="n">Some</span> <span class="n">predictor</span> <span class="n">variables</span> <span class="n">are</span> <span class="n">on</span> <span class="n">very</span> <span class="n">different</span> <span class="n">scales</span><span class="o">:</span> <span class="n">consider</span> <span class="n">rescaling</span> 
<span class="o">&gt;</span> <span class="n">ranef</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
<span class="o">$</span><span class="n">day</span>
   <span class="p">(</span><span class="n">Intercept</span><span class="p">)</span>
<span class="n">fr</span>           <span class="m">0</span>
<span class="n">mo</span>           <span class="m">0</span>
<span class="n">sa</span>           <span class="m">0</span>
<span class="n">su</span>           <span class="m">0</span>
<span class="n">th</span>           <span class="m">0</span>
<span class="n">tu</span>           <span class="m">0</span>
<span class="n">we</span>           <span class="m">0</span>

<span class="o">&gt;</span> <span class="n">VarCorr</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
 <span class="n">Groups</span>   <span class="n">Name</span>        <span class="n">Std.Dev.</span>
 <span class="n">day</span>      <span class="p">(</span><span class="n">Intercept</span><span class="p">)</span> <span class="m">0.0000</span>  
 <span class="n">Residual</span>             <span class="m">1.2614</span>
</code></pre>
</div>

<p>Unfortunately, <code class="highlighter-rouge">mixed_models</code> is rather slow when applied to such a large data set (<code class="highlighter-rouge">blog_data</code> is a data frame of size 22435×8), especially when compared to <code class="highlighter-rouge">lme4</code> which uses many sparse matrix tricks and is mostly written in C++ (integrated in R via <code class="highlighter-rouge">Rcpp</code>) to speed up computation. The difference in performance between <code class="highlighter-rouge">mixed_models</code> and <code class="highlighter-rouge">lme4</code> is on the order of hours for large data, and Julia’s <code class="highlighter-rouge">MixedModels.jl</code> promises to be even faster than <code class="highlighter-rouge">lme4</code>. However, there is no noticeable difference in performance speed for smaller data sets.</p>

<p><a href="http://nbviewer.ipython.org/github/agisga/mixed_models/blob/master/notebooks/blog_data.ipynb">The full data analysis of the blog post data can be found in this IRuby notebook</a>.</p>

<h3 id="a-second-example-and-statistical-inference-on-the-parameter-estimates">A second example and statistical inference on the parameter estimates</h3>

<p>Often, the experimental design or the data suggests a linear mixed model whose random effects are associated with multiple grouping factors. A specification of multiple random effects terms which correspond to multiple grouping factors is often referred to as <em>crossed random effect</em>, or <em>nested random effects</em> if the corresponding grouping factors are nested in each other. A good reference on such models is <a href="http://lme4.r-forge.r-project.org/book/Ch2.pdf">Chapter 2</a> of Douglas Bates’ <code class="highlighter-rouge">lme4</code> book.</p>

<p>Like <code class="highlighter-rouge">lme4</code>, <code class="highlighter-rouge">mixed_models</code> is particularly well suited for models with crossed or nested random effects. The current release of <code class="highlighter-rouge">statmodels</code>, however, does not support crossed or nested random effects (according to the <a href="http://statsmodels.sourceforge.net/devel/mixed_linear.html">documentation</a>).</p>

<p>As an example we fit a linear mixed model with nested random effects to a data frame with 100 rows, of the form:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c1">#&lt;Daru::DataFrame:69912847885160 @name = 2b161c5d-00de-4240-be50-8fa84f3aed24 @size = 5&gt;</span>
                    <span class="n">a</span>          <span class="n">b</span>          <span class="n">x</span>          <span class="n">y</span> 
         <span class="mi">0</span>         <span class="n">a3</span>         <span class="n">b1</span> <span class="mi">0</span><span class="o">.</span><span class="mi">38842531</span> <span class="mi">5</span><span class="o">.</span><span class="mi">10364866</span> 
         <span class="mi">1</span>         <span class="n">a3</span>         <span class="n">b2</span> <span class="mi">0</span><span class="o">.</span><span class="mi">44622300</span> <span class="mi">6</span><span class="o">.</span><span class="mi">23307061</span> 
         <span class="mi">2</span>         <span class="n">a3</span>         <span class="n">b1</span> <span class="mi">1</span><span class="o">.</span><span class="mi">54993657</span> <span class="mi">12</span><span class="o">.</span><span class="mi">2050404</span> 
         <span class="mi">3</span>         <span class="n">a3</span>         <span class="n">b1</span> <span class="mi">1</span><span class="o">.</span><span class="mi">52786614</span> <span class="mi">12</span><span class="o">.</span><span class="mo">00675</span><span class="mi">95</span> 
         <span class="mi">4</span>         <span class="n">a3</span>         <span class="n">b2</span> <span class="mi">0</span><span class="o">.</span><span class="mi">76011212</span> <span class="mi">8</span><span class="o">.</span><span class="mi">20054527</span>
</code></pre>
</div>

<p>We consider the following model:</p>

<ul>
  <li>We take <code class="highlighter-rouge">y</code> to be the response and <code class="highlighter-rouge">x</code> its predictor.</li>
  <li>We consider the factor <code class="highlighter-rouge">b</code> to be nested within the factor <code class="highlighter-rouge">a</code>.</li>
  <li>We assume that the intercept varies due to variable <code class="highlighter-rouge">a</code>; that is, a different (random) intercept term for each level of <code class="highlighter-rouge">a</code>.</li>
  <li>Moreover, we assume that the intercept varies due to the factor <code class="highlighter-rouge">b</code> which is nested in <code class="highlighter-rouge">a</code>; that is, different (random) intercept for each combination of levels of <code class="highlighter-rouge">a</code> and <code class="highlighter-rouge">b</code>.</li>
</ul>

<p>That is, mathematically the model can be expressed as</p>

<div class="highlighter-rouge"><pre class="highlight"><code>y = beta_0 + beta_1 * x + gamma(a) + delta(a,b) + epsilon
</code></pre>
</div>

<p>where <code class="highlighter-rouge">gamma(a) ~ N(0, phi**2)</code> and <code class="highlighter-rouge">delta(a,b) ~ N(0, psi**2)</code> are normally distributed random variables which assume different realizations for different values of <code class="highlighter-rouge">a</code> and <code class="highlighter-rouge">b</code>, and where <code class="highlighter-rouge">epsilon</code> is a random Gaussian noise term with variance <code class="highlighter-rouge">sigma**2</code>. The goal is to estimate the parameters <code class="highlighter-rouge">beta_0</code>, <code class="highlighter-rouge">beta_1</code>, <code class="highlighter-rouge">phi</code>, <code class="highlighter-rouge">psi</code> and <code class="highlighter-rouge">sigma</code>.</p>

<p>We fit this model in <code class="highlighter-rouge">mixed_models</code>, and display the estimated random effects correlation structure with</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">mod</span> <span class="o">=</span> <span class="no">LMM</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="ss">formula: </span><span class="s2">"y ~ x + (1|a) + (1|a:b)"</span><span class="p">,</span> 
                       <span class="ss">data: </span><span class="n">df</span><span class="p">,</span> <span class="ss">reml: </span><span class="kp">false</span><span class="p">)</span>
<span class="nb">puts</span> <span class="n">mod</span><span class="p">.</span><span class="nf">ran_ef_summary</span><span class="p">.</span><span class="nf">inspect</span>
</code></pre>
</div>

<p>which produces the output</p>

<div class="highlighter-rouge"><pre class="highlight"><code>                    a    a_and_b 
         a 1.34108300        nil 
   a_and_b        nil 0.97697500
</code></pre>
</div>

<p>The correlation between the factor <code class="highlighter-rouge">a</code> and the nested random effect <code class="highlighter-rouge">a_and_b</code> is denoted as <code class="highlighter-rouge">nil</code>, because the random effects in the model at hand are assumed to be independent.</p>

<p>An advantage of <code class="highlighter-rouge">mixed_models</code> over some other tools is the simplicity with which p-values and confidence intervals for the parameter estimates can be calculated using a multitude of available methods. Such methods include a likelihood ratio test implementation, multiple bootstrap based methods (which run in parallel by default), and methods based on the Wald Z statistic.</p>

<p>We can compute five types of 95% confidence intervals for the fixed effects coefficients with the following line of code:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">mod</span><span class="p">.</span><span class="nf">fix_ef_conf_int</span><span class="p">(</span><span class="ss">method: :all</span><span class="p">,</span> <span class="ss">nsim: </span><span class="mi">1000</span><span class="p">)</span>
</code></pre>
</div>

<p>which yields the result</p>

<div class="highlighter-rouge"><pre class="highlight"><code>                                          intercept                                        x 
    wald_z [-1.0442515623151203, 2.433416817887737]   [4.302419420148841, 5.038899876985704] 
boot_basic [-0.9676586601496888, 2.486799230544233]    [4.30540212917657, 5.028701160534481] 
 boot_norm [-1.0575520080398213, 2.4667867000424115   [4.295959190826356, 5.043382379744274] 
    boot_t [-0.9676586601496886, 2.486799230544233]    [4.30540212917657, 5.028701160534481] 
 boot_perc [-1.0976339749716164, 2.3568239157223054   [4.312618136600064, 5.035917167957975] 

</code></pre>
</div>

<p>For example, we see here that the intercept term is likely not significantly different from zero. We could proceed now by performing hypotheses tests using <code class="highlighter-rouge">#fix_ef_p</code> or <code class="highlighter-rouge">#likelihood_ratio_test</code>, or by refitting a model without an intercept using <code class="highlighter-rouge">#drop_fix_ef</code>.</p>

<p>We can also test the nested random effect for significance, in order to decide whether we should drop that term from the model to reduce model complexity. We can use a bootstrap based version of likelihood ratio test as follows.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">mod</span><span class="p">.</span><span class="nf">ran_ef_p</span><span class="p">(</span><span class="ss">variable: :intercept</span><span class="p">,</span> <span class="ss">grouping: </span><span class="p">[</span><span class="ss">:a</span><span class="p">,</span> <span class="ss">:b</span><span class="p">],</span> 
             <span class="ss">method: :bootstrap</span><span class="p">,</span> <span class="ss">nsim: </span><span class="mi">1000</span><span class="p">)</span>
</code></pre>
</div>

<p>We get a p-value of 9.99e-4, suggesting that we probably should keep the term <code class="highlighter-rouge">(1|a:b)</code> in the model formula.</p>

<h3 id="a-third-example-mdash-a-less-conventional-model-fit">A third example — a less conventional model fit</h3>

<p>Another advantage of <code class="highlighter-rouge">mixed_models</code> against comparable tools is the ease of fitting models with arbitrary covariance structures of the random effects, which are not covered by the formula interface of <code class="highlighter-rouge">lme4</code>. This can be done in a user-friendly manner by providing a block or a <code class="highlighter-rouge">Proc</code> to the <code class="highlighter-rouge">LMM</code> constructor. This unique feature of the Ruby language makes the implementation and usage of the method incredibly convenient. A danger of allowing for arbitrary covariance structures is, of course, that such a flexibility gives the user the freedom to specify degenerate and computationally unstable  models.</p>

<p>As an example we look at an application to genetics, namely to SNP data (<a href="https://en.wikipedia.org/wiki/Single-nucleotide_polymorphism">single-nucleotide polymorphism</a>) with known pedigree structures (family relationships of the subjects). The family information is prior knowledge that we can model in the random effects of a linear mixed effects model.</p>

<p>We model the quantitative trait <code class="highlighter-rouge">y</code> (a vector of length 1200) as</p>

<div class="highlighter-rouge"><pre class="highlight"><code>y = X * beta + b + epsilon,
</code></pre>
</div>

<p>where <code class="highlighter-rouge">X</code> is a <code class="highlighter-rouge">1200 x 130</code> matrix containing the genotypes (i.e. 130 SNPs for each of the 1200 subjects); <code class="highlighter-rouge">epsilon</code> is a vector of independent random noise terms with variances equal to <code class="highlighter-rouge">sigma**2</code>; <code class="highlighter-rouge">beta</code> is a vector of unknown fixed effects coefficients measuring the contribution of each SNP to the quantitative trait <code class="highlighter-rouge">y</code>; and <code class="highlighter-rouge">b</code> is a vector of random effects.</p>

<p>If we denote the kinship matrix by <code class="highlighter-rouge">K</code>, then we can express the probability distribution of <code class="highlighter-rouge">b</code> as <code class="highlighter-rouge">b ~ N(0, delta**2 * 2 * K)</code>, where we multiply <code class="highlighter-rouge">K</code> by <code class="highlighter-rouge">2</code> because the diagonal of <code class="highlighter-rouge">K</code> is constant <code class="highlighter-rouge">0.5</code>, and where <code class="highlighter-rouge">delta**2</code> is a unknown scaling factor.</p>

<p>The goal is to estimate the unknown parameters <code class="highlighter-rouge">beta</code>, <code class="highlighter-rouge">sigma</code>, and <code class="highlighter-rouge">delta</code>, and to determine which of the fixed effects coefficients are significantly different from 0 (i.e. which SNPs are possibly causing the variability in the trait <code class="highlighter-rouge">y</code>).</p>

<p>In order to specify the covariance structure of the random effects, we need to pass a block or <code class="highlighter-rouge">Proc</code> that produces the upper triangular Cholesky factor of the covariance matrix of the random effects from an input Array. In this example, that would be the multiplication of the prior known Cholesky factor of the kinship matrix with a scaling factor.</p>

<p>Having all the model matrices and vectors, we compute the Cholesky factor of the kinship matrix and fit the model with</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c1"># upper triangulat Cholesky factor</span>
<span class="n">kinship_mat_cholesky_factor</span> <span class="o">=</span> <span class="n">kinship_mat</span><span class="p">.</span><span class="nf">factorize_cholesky</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 

<span class="c1"># Fit the model</span>
<span class="n">model_fit</span> <span class="o">=</span> <span class="no">LMM</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="ss">x: </span><span class="n">x</span><span class="p">,</span> <span class="ss">y: </span><span class="n">y</span><span class="p">,</span> <span class="ss">zt: </span><span class="n">z</span><span class="p">,</span>
                    <span class="ss">x_col_names: </span><span class="n">x_names</span><span class="p">,</span> 
                    <span class="ss">start_point: </span><span class="p">[</span><span class="mi">2</span><span class="o">.</span><span class="mi">0</span><span class="p">],</span> 
                    <span class="ss">lower_bound: </span><span class="p">[</span><span class="mi">0</span><span class="o">.</span><span class="mi">0</span><span class="p">])</span> <span class="p">{</span> <span class="o">|</span><span class="n">th</span><span class="o">|</span> <span class="n">kinship_mat_cholesky_factor</span> <span class="o">*</span> <span class="n">th</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">}</span>
</code></pre>
</div>

<p>Then we can use the available hypotheses test and confidence interval methods to determine which SNPs are significant predictors of the quantitative trait. Out of the 130 SNPs in the model, we find 24 to be significant as linear predictors.</p>

<p>See <a href="http://agisga.github.io/mixed_models_applied_to_family_SNP_data/">this blog post</a> for a full analysis of this data with <code class="highlighter-rouge">mixed_models</code>.</p>

<h2 id="room-for-improvement-and-future-work">Room for improvement and future work</h2>

<ul>
  <li>
    <p>Writing the formula language interpretation code used by <code class="highlighter-rouge">LMM#from_formula</code> from scratch was not easy. Much of the code can be reorganized to be easier to read and to use in other projects. Possibly, the formula interface should be separated out, similar to how it is done with the Python package <a href="https://github.com/pydata/patsy">patsy</a>. Also, some shortcut symbols (namely <code class="highlighter-rouge">*</code>, <code class="highlighter-rouge">/</code>, and <code class="highlighter-rouge">||</code>) in the model specification formula language are currently not implemented.</p>
  </li>
  <li>
    <p>I plan to add linear mixed models for high-dimensional data (i.e. more predictors than observations) to <code class="highlighter-rouge">mixed_models</code>, because that work would be in line with my current PhD research.</p>
  </li>
  <li>
    <p>I plan to add generalized linear mixed models capabilities to <code class="highlighter-rouge">mixed_models</code>, which can be used to fit mixed models to discrete data (such as binary or count data).</p>
  </li>
</ul>

<h2 id="acknowledgement">Acknowledgement</h2>

<p>I want to thank Google and the <a href="sciruby.com">Ruby Science Foundation</a> for giving me this excellent opportunity! I especially want to thank <a href="http://thebird.nl/">Pjotr Prins</a> who was my mentor for the project for much helpful advice and suggestions as well as his prompt responses to any of my concerns. I also want to thank my fellow GSoC participants <a href="https://github.com/wlevine">Will</a>, <a href="https://github.com/dilcom">Ivan</a>, and <a href="https://github.com/v0dro">Sameer</a> for their help with certain aspects of my project.</p>

  </div>

  <div class="date">
    Written on August 19, 2015
  </div>

  <div class="date">
    Tags:
		
		<a href="/tag/ruby">#ruby</a>
		
		<a href="/tag/mixed_models">#mixed_models</a>
		
		<a href="/tag/regression">#regression</a>
		
		<a href="/tag/LMM">#LMM</a>
		
  </div>

  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'agisga';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          



<a href="https://github.com/agisga"><i class="svg-icon github"></i></a>

<a href="https://www.linkedin.com/in/alexejgossmann"><i class="svg-icon linkedin"></i></a>

<a href="/feed.xml"><i class="svg-icon rss"></i></a>
<a href="https://www.twitter.com/agisga"><i class="svg-icon twitter"></i></a>



        </footer>
      </div>
    </div>

    

  </body>
</html>
