<!DOCTYPE html>
<html>
  <head>
    <title>A (naive) application of linear mixed models to genetics – Alexej Gossmann – I am interested in math, stats, coding, genetics, ...</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="The following shows an application of class LMM from the Ruby gem mixed_models to SNP data (single-nucleotide polymorphism) with known pedigree structures. The family information is prior knowledge that we can model in the random effects of a linear mixed effects model.
" />
    <meta property="og:description" content="The following shows an application of class LMM from the Ruby gem mixed_models to SNP data (single-nucleotide polymorphism) with known pedigree structures. The family information is prior knowledge that we can model in the random effects of a linear mixed effects model.
" />
    
    <meta name="author" content="Alexej Gossmann" />

    
    <meta property="og:title" content="A (naive) application of linear mixed models to genetics" />
    <meta property="twitter:title" content="A (naive) application of linear mixed models to genetics" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Alexej Gossmann - I am interested in math, stats, coding, genetics, ..." href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
 
    <!-- MathJax interation-->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [["$","$"]]}});
      MathJax.Hub.Config({TeX: {Macros:{subscript:['_{#1}',1],superscript:['^{#1}',1]}}});
    </script> 
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full">
    </script>
 </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://avatars0.githubusercontent.com/u/11449372?v=3&s=460" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Alexej Gossmann</a></h1>
            <p class="site-description">I am interested in math, stats, coding, genetics, ...</p>
          </div>

          <nav>
            <a href="/about">About</a>
            <a href="/">Blog</a>
            <a href="/talks">Presentations</a>
            <a href="/publications">Publications</a>
            <a href="/software">Software</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>A (naive) application of linear mixed models to genetics</h1>

  <div class="entry">
    <p>The following shows an application of class <code>LMM</code> from the Ruby gem <a href="https://github.com/agisga/mixed_models.git"><code>mixed_models</code></a> to SNP data (<a href="https://en.wikipedia.org/wiki/Single-nucleotide_polymorphism">single-nucleotide polymorphism</a>) with known pedigree structures. The family information is prior knowledge that we can model in the random effects of a linear mixed effects model.</p>

<h2>Data</h2>

<p>I have simulated realistic SNP data with the simulation software <a href="http://seqsimla.sourceforge.net/">SeqSIMLA</a>, using the software <a href="http://www.broadinstitute.org/%7Esfs/cosi/">cosi</a> to generate a reference sequence, as advised in the SeqSIMLA <a href="http://seqsimla.sourceforge.net/tutorial.html">tutorial</a>.</p>

<p>The response variable is a quantitative trait with mean 10 and variance 1. In total there are 130 SNPs in the data set, and SNPs 1, 3, 5 and 11 are selected to be causal, explaining 10%, 20%, 20% and 10% of the variance in the quantitative trait. Additionally, 35% of the variance is explained by shared environmental effects, and the remaining 5% by individual environmental effects. The correlation coefficient between spouses for the shared environmental effects is set to 0.8, and the respective correlation coefficients between parent and offspring as well as siblings is set to be 0.5. The data is available for ten families of twelve individuals each (i.e. 1200 subjects total). All families have identical pedigrees, which look like this:
<img src="/images/pedigree.jpeg?raw=true" alt="Image of pedigree"></p>

<p>The exact parameters provided to the SeqSIMLA software can be found in a <a href="https://github.com/agisga/mixed_models/blob/master/examples/genetics/data/data_generation_and_preprocessing/SeqSIMLA_Call.txt">text file in the repository</a>. Additionally, I have preprocessed the SeqSIMLA output slightly and extracted the <a href="https://en.wikipedia.org/wiki/Kinship">kinship</a> matrix, both using a short <a href="https://github.com/agisga/mixed_models/blob/master/examples/genetics/data/data_generation_and_preprocessing/preprocessing.R">R script</a>.</p>

<h2>The model</h2>

<p>We model the quantitative trait $y$ (a vector of length 1200) as,
$$y = X\beta + b + \epsilon,$$
where $X$ is a $1200\times 130$ matrix containing the genotypes, $\epsilon$ is a vector of i.i.d. random residuals with variances equal to $\sigma\subscript{e}^2$, $\beta$ is a vector of unknown fixed effects coefficients, and $b$ is a vector of random effects.</p>

<p>If we denote the kinship matrix by $K$, then we can express the probability distribution of $b$ as
$$b\sim N(0, \sigma\subscript{b}^2 2K),$$
where we multiply $K$ by $2$ because the diagonal of $K$ is constant $0.5$, and where $\sigma\subscript{b}^2$ is a scaling factor.</p>

<p>The goal is to estimate the unknown parameters $\beta$, $\sigma\subscript{e}^2$ and $\sigma\subscript{b}^2$, and to determine which of the fixed effects coefficients are significantly different from 0 (i.e. which SNPs are possibly causing the variability in the phenotype).</p>

<h2>Fit the model in Ruby</h2>

<p>First, we need to load the generated design matrix $X$, the response vector $y$, and the kinship matrix $K$.</p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="k">def</span> <span class="nf">read_csv_into_array</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
  <span class="n">f</span> <span class="o">=</span> <span class="no">File</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
  <span class="n">lines_array</span> <span class="o">=</span> <span class="nb">Array</span><span class="o">.</span><span class="n">new</span>
  <span class="n">f</span><span class="o">.</span><span class="n">each_line</span> <span class="p">{</span> <span class="o">|</span><span class="n">line</span><span class="o">|</span> <span class="n">lines_array</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="p">}</span>
  <span class="n">f</span><span class="o">.</span><span class="n">close</span>
  <span class="n">lines_array</span><span class="o">.</span><span class="n">each_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span> 
    <span class="n">lines_array</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">=</span> <span class="n">lines_array</span><span class="o">[</span><span class="n">i</span><span class="o">].</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span> 
    <span class="n">lines_array</span><span class="o">[</span><span class="n">i</span><span class="o">].</span><span class="n">each_index</span> <span class="p">{</span> <span class="o">|</span><span class="n">j</span><span class="o">|</span> <span class="n">lines_array</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">j</span><span class="o">]</span> <span class="o">=</span> <span class="n">lines_array</span><span class="o">[</span><span class="n">i</span><span class="o">][</span><span class="n">j</span><span class="o">].</span><span class="n">to_f</span> <span class="p">}</span>
  <span class="k">end</span>
  <span class="k">return</span> <span class="n">lines_array</span>
<span class="k">end</span>

<span class="c1"># fixed effects design matrix</span>
<span class="n">x_array</span> <span class="o">=</span> <span class="n">read_csv_into_array</span><span class="p">(</span><span class="s2">&quot;./data/design_matrix.csv&quot;</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">x_array</span><span class="o">.</span><span class="n">length</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">x_array</span><span class="o">[</span><span class="mi">0</span><span class="o">].</span><span class="n">length</span>
<span class="n">x_array</span><span class="o">.</span><span class="n">unshift</span><span class="p">(</span><span class="nb">Array</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="p">{</span><span class="mi">1</span><span class="o">.</span><span class="mi">0</span><span class="p">})</span> <span class="c1"># intercept</span>
<span class="n">x</span> <span class="o">=</span> <span class="no">NMatrix</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="o">]</span><span class="p">,</span> <span class="n">x_array</span><span class="o">.</span><span class="n">flatten</span><span class="p">,</span> <span class="ss">dtype</span><span class="p">:</span> <span class="ss">:float64</span><span class="p">)</span>

<span class="c1"># response vector</span>
<span class="n">y_array</span> <span class="o">=</span> <span class="n">read_csv_into_array</span><span class="p">(</span><span class="s2">&quot;./data/phenotype.csv&quot;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="no">NMatrix</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">[</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="o">]</span><span class="p">,</span> <span class="n">y_array</span><span class="o">.</span><span class="n">flatten</span><span class="p">,</span> <span class="ss">dtype</span><span class="p">:</span> <span class="ss">:float64</span><span class="p">)</span>

<span class="c1"># kinship matrix, which determines the random effects covariance matrix</span>
<span class="n">kinship_array</span> <span class="o">=</span> <span class="n">read_csv_into_array</span><span class="p">(</span><span class="s2">&quot;./data/kinship_matrix.csv&quot;</span><span class="p">)</span>
<span class="n">kinship_mat</span> <span class="o">=</span> <span class="no">NMatrix</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">[</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="o">]</span><span class="p">,</span> <span class="n">kinship_array</span><span class="o">.</span><span class="n">flatten</span><span class="p">,</span> <span class="ss">dtype</span><span class="p">:</span> <span class="ss">:float64</span><span class="p">)</span>
</code></pre></div>
<p>Now, we can try to fit the model.</p>

<p>Instead of using the user-friendly method <code>LMM#from_formula</code> to fit the model, we will fit the model with raw model matrices directly using <code>LMM#initialize</code>. While <code>LMM#from_formula</code> mimics the behaviour of the function <code>lmer</code> from the popular <code>R</code> package <code>lme4</code> (see my <a href="http://agisga.github.io/MixedModels_from_formula/">previous</a> blog <a href="http://agisga.github.io/MixedModels_p_values_and_CI/">posts</a>), <code>LMM#initialize</code> gives more flexibility to the user and allows for less conventional fits, which (to my knowledge) are not directly covered by <code>lme4</code>. This flexibility comes in form of an interface, where the user can supply the parametrization for the triangular Cholesky factor of the covariance matrix of the random effects in form of a <code>Proc</code> object or a block (which probably would not be as nice syntactically in most other languages as it is in Ruby).</p>

<p>In this case, the Cholesky factor of the covariance matrix is $\sqrt{2} \sigma\subscript{b} \Lambda$, where $\Lambda$ is the Cholesky factor of the kinship matrix $K$. For convenience, we use the transformation $\theta = \sqrt{2} \sigma\subscript{b}$.</p>

<p>Before we call <code>LMM.new</code>, we also need to define the random effects model matrix $Z$ (which is the identity matrix in this case), find the Cholesky factor $\Lambda$ of the kinship matrix $K$, and specify the column names for the SNP matrix $X$. These steps and the model fit are performed by the following Ruby code.</p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="nb">require</span> <span class="s1">&#39;mixed_models&#39;</span>

<span class="n">z</span> <span class="o">=</span> <span class="no">NMatrix</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="o">[</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="o">]</span><span class="p">,</span> <span class="ss">dtype</span><span class="p">:</span> <span class="ss">:float64</span><span class="p">)</span>

<span class="c1"># upper triangulat Cholesky factor</span>
<span class="n">kinship_mat_cholesky_factor</span> <span class="o">=</span> <span class="n">kinship_mat</span><span class="o">.</span><span class="n">factorize_cholesky</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span> 

<span class="c1"># fixed effects names</span>
<span class="n">x_names</span> <span class="o">=</span> <span class="o">[</span><span class="ss">:Intercept</span><span class="o">]</span>
<span class="mi">1</span><span class="o">.</span><span class="n">upto</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="n">x_names</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="s2">&quot;SNP</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">to_sym</span><span class="p">)</span> <span class="p">}</span>

<span class="c1"># Fit the model</span>
<span class="n">model_fit</span> <span class="o">=</span> <span class="no">LMM</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="ss">y</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span> <span class="ss">zt</span><span class="p">:</span> <span class="n">z</span><span class="p">,</span>
                    <span class="ss">x_col_names</span><span class="p">:</span> <span class="n">x_names</span><span class="p">,</span> 
                    <span class="ss">start_point</span><span class="p">:</span> <span class="o">[</span><span class="mi">2</span><span class="o">.</span><span class="mi">0</span><span class="o">]</span><span class="p">,</span> 
                    <span class="ss">lower_bound</span><span class="p">:</span> <span class="o">[</span><span class="mi">0</span><span class="o">.</span><span class="mi">0</span><span class="o">]</span><span class="p">)</span> <span class="p">{</span> <span class="o">|</span><span class="n">th</span><span class="o">|</span> <span class="n">kinship_mat_cholesky_factor</span> <span class="o">*</span> <span class="n">th</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span> <span class="p">}</span>
</code></pre></div>
<p>It takes a couple of minutes to run.</p>

<h2>Results</h2>

<p>We can start by looking at some parameters describing the model fit:</p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="nb">puts</span> <span class="s2">&quot;Optimal theta: </span><span class="se">\t</span><span class="si">#{</span><span class="n">model_fit</span><span class="o">.</span><span class="n">theta</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">puts</span> <span class="s2">&quot;REML criterion: </span><span class="se">\t</span><span class="si">#{</span><span class="n">model_fit</span><span class="o">.</span><span class="n">deviance</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div>
<p>yields</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Optimal theta:  [2.508012294769287]
REML criterion:     3919.756682815396
</code></pre></div>
<p>(I know not very meaningful to look at... At least, we see that the optimization method converged.)</p>

<p>Now, we might be interested to see which of the SNPs explain the variation in the quantitative trait best. To this end, we print those SNPs to the screen, which have a Wald p-value less than 0.05 (<a href="http://agisga.github.io/MixedModels_p_values_and_CI/">I have written before about Wald Z tests not being adequate</a>, also see <strong>update</strong> below).</p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="n">p_vals</span> <span class="o">=</span> <span class="n">model_fit</span><span class="o">.</span><span class="n">fix_ef_p</span>
<span class="n">p_signif</span> <span class="o">=</span> <span class="nb">Array</span><span class="o">.</span><span class="n">new</span>
<span class="n">p_vals</span><span class="o">.</span><span class="n">each_key</span> <span class="p">{</span> <span class="o">|</span><span class="n">k</span><span class="o">|</span> <span class="n">p_signif</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_vals</span><span class="o">[</span><span class="n">k</span><span class="o">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">.</span><span class="mo">05</span> <span class="p">}</span>
<span class="nb">puts</span> <span class="s2">&quot;Fixed effects with Wald p-values &lt;0.05:&quot;</span>
<span class="nb">puts</span> <span class="n">p_signif</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="p">)</span>
</code></pre></div>
<p>We get:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">SNP2, SNP7, SNP10, SNP11, SNP13, SNP15, SNP24, SNP25, SNP26, 
SNP40, SNP41, SNP42, SNP51, SNP52, SNP53, SNP55, SNP62, SNP85, 
SNP96, SNP100, SNP102, SNP106, SNP107, SNP125, SNP127
</code></pre></div>
<p>Because the data is simulated, we know that the true causal SNPs are #1, #3, #5 and #11. The model only picked up SNP #11 among those. However, this is not surprising, because SNP data is highly correlated. The selected SNPs are probably highly correlated to the true casual ones, and because of random fluctuations, in this particular data set they probably happened to explain the response better than the true causal SNPs. </p>

<p>Also, it might be of interest to see just how much of the remaining (not-explained-by-SNPs) variability of the response is explained by family relatedness as compared to individual random fluctuations of each subject. We address this question by comparing the estimates of $\sigma\subscript{b}^2$ and $\sigma\subscript{e}^2$.</p>

<p>Because $\theta$ is the scaling factor of the Cholesky factor $\Lambda$ of the kinship matrix $K$, and the covariance of the random effects $b$ is given by
$$\Sigma = \sigma\subscript{b}^2 2K = (\theta \Lambda) (\theta \Lambda^T),$$
it follows that
$$\sigma\subscript{b}^2 = \theta^2 / 2.$$ </p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="nb">puts</span> <span class="s2">&quot;Variance due to family relatedness: </span><span class="se">\t</span><span class="si">#{</span><span class="n">model_fit</span><span class="o">.</span><span class="n">theta</span><span class="o">[</span><span class="mi">0</span><span class="o">]**</span><span class="mi">2</span><span class="o">.</span><span class="mi">0</span> <span class="o">/</span> <span class="mi">2</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="nb">puts</span> <span class="s2">&quot;Residual variance: </span><span class="se">\t</span><span class="si">#{</span><span class="n">model_fit</span><span class="o">.</span><span class="n">sigma2</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div>
<p>We see that as expected from the SeqSIMLA input parameters mentioned above, the family relatedness influences the total variance of the trait a lot more than individual non-genetic factors.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Variance due to family relatedness:     3.1450628353569527
Residual variance:  0.3189292035466212
</code></pre></div>
<hr>

<h2>Update</h2>

<p>As an alternative to the Wald Z tests performed above we can make use of the equivalence of confidence intervals and significance tests. That is, if the 95% confidence interval of a fixed effect does not include zero, then the fixed effect coefficient in question differs from zero with a p-value of 0.05.
I have summarized different types of bootstrap confidence intervals available in <code>mixed_models</code> in a <a href="http://agisga.github.io/bootstap_confidence_intervals/">blog post</a>.
We can compute studentized bootstrap confidence intervals with 95% coverage using the following code.</p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="n">ci_bootstrap</span> <span class="o">=</span> <span class="n">model_fit</span><span class="o">.</span><span class="n">fix_ef_conf_int</span><span class="p">(</span><span class="nb">method</span><span class="p">:</span> <span class="ss">:bootstrap</span><span class="p">,</span> <span class="ss">nsim</span><span class="p">:</span> <span class="mi">1000</span><span class="p">)</span>
</code></pre></div>
<p>Due to the size of the data (1200 observations of 130 variables) the 1000 performed bootstrap simulations ran for more then 10 hours on my laptop (Intel Core i5 processor of fifth generation). Instead of examining all confidence intervals, I only print those which do not contain zero, using the following code.</p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="n">ci_signif</span> <span class="o">=</span> <span class="no">Hash</span><span class="o">.</span><span class="n">new</span>
<span class="n">ci_bootstrap</span><span class="o">.</span><span class="n">each_key</span> <span class="k">do</span> <span class="o">|</span><span class="n">key</span><span class="o">|</span>
  <span class="c1"># check if the CI contains 0</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">ci_bootstrap</span><span class="o">[</span><span class="n">key</span><span class="o">][</span><span class="mi">0</span><span class="o">]</span> <span class="o">*</span> <span class="n">ci_bootstrap</span><span class="o">[</span><span class="n">key</span><span class="o">][</span><span class="mi">1</span><span class="o">]</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">then</span>
    <span class="n">ci_signif</span><span class="o">[</span><span class="n">key</span><span class="o">]</span> <span class="o">=</span> <span class="n">ci_bootstrap</span><span class="o">[</span><span class="n">key</span><span class="o">]</span>
  <span class="k">end</span>
<span class="k">end</span>
<span class="nb">puts</span> <span class="s2">&quot;Studentized bootstrap confidence intervals not containing zero:&quot;</span>
<span class="nb">puts</span> <span class="n">ci_signif</span>
</code></pre></div>
<p>Which yields:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Studentized bootstrap confidence intervals not containing zero:
{:SNP2=&gt;[0.02102004268473849, 0.19723382621979196], 
:SNP7=&gt;[0.024429922300370194, 0.2050671130468381], 
:SNP10=&gt;[0.03459252399249489, 0.21426082763890741], 
:SNP11=&gt;[0.08911647130840533, 0.2734691844585601], 
:SNP13=&gt;[0.0456727118052626, 0.22425364463936825], 
:SNP15=&gt;[0.03181623273320287, 0.21173723808641784], 
:SNP25=&gt;[0.01986561195551105, 0.19729703681731675], 
:SNP26=&gt;[0.016293023488597055, 0.20877970806848856], 
:SNP40=&gt;[0.041118439272559176, 0.21138427319736441], 
:SNP41=&gt;[0.020204375347575798, 0.20732073954994756], 
:SNP42=&gt;[0.03651940469509106, 0.2140755606301379], 
:SNP51=&gt;[0.052484169516553617, 0.24343113789170623], 
:SNP52=&gt;[0.03286133268033546, 0.2095456450883188], 
:SNP53=&gt;[0.017970201451067855, 0.2106064389500535], 
:SNP55=&gt;[0.027856517149911247, 0.2048122682390223], 
:SNP62=&gt;[0.049097681406648525, 0.23149634299539168], 
:SNP85=&gt;[0.014276199187678293, 0.1942775690073427], 
:SNP96=&gt;[0.001038435570539148, 0.18219718091237833], 
:SNP100=&gt;[0.0028378036113550775, 0.19694912960692745], 
:SNP102=&gt;[0.029119574583789387, 0.20291901799020484], 
:SNP106=&gt;[0.0071595998238537795, 0.18495009016791536], 
:SNP107=&gt;[0.008993896956614525, 0.19396696934223592], 
:SNP125=&gt;[0.04701107230060422, 0.22696673801664247], 
:SNP127=&gt;[0.006116174706046959, 0.1803563547638151]}
</code></pre></div>
<p>As the Wald Z tests above, the studentized bootstrap methods detects only one of the true causal SNPs #1, #3, #5 and #11. As explained above, this happens because of very high correlations between the SNPs. </p>

<p>Another question that we may want to answer is how similar the results of the studentized bootstrap method are to those of the Wald Z tests. To answer that question we look at the intersection of the two sets of selected SNPs. The code</p>
<div class="highlight"><pre><code class="language-Ruby" data-lang="Ruby"><span class="nb">puts</span> <span class="s2">&quot;SNPs that have Wald p-values &lt;.05 and studentized bootstrap confidence intervals not containing zero:&quot;</span>
<span class="nb">puts</span> <span class="p">(</span><span class="n">ci_signif</span><span class="o">.</span><span class="n">keys</span> <span class="o">&amp;</span> <span class="n">p_signif</span><span class="p">)</span>
</code></pre></div>
<p>produces the output</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">SNPs that have Wald p-values &lt;.05 and studentized bootstrap confidence intervals not containing zero:
SNP2
SNP7
SNP10
SNP11
SNP13
SNP15
SNP25
SNP26
SNP40
SNP41
SNP42
SNP51
SNP52
SNP53
SNP55
SNP62
SNP85
SNP96
SNP100
SNP102
SNP106
SNP107
SNP125
SNP127
</code></pre></div>
<p>We see that 24 out of the 25 SNPs detected by the Wald Z tests were also detected by the bootstrap method. In fact, it turns out that the set of SNPs detected by the studentized bootstrap is a subset of the SNP set identified by the Wald Z tests. The reason for this behaviour is probably that the fixed effects coefficient estimates are approximately normally distributed for the given data (which in itself is a interesting discovery).</p>

  </div>

  <div class="date">
    Written on July  7, 2015
  </div>

  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'agisga';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          



<a href="http://github.com/agisga"><i class="svg-icon github"></i></a>

<a href="http://linkedin.com/in/alexejgossmann"><i class="svg-icon linkedin"></i></a>


<a href="http://twitter.com/agisga"><i class="svg-icon twitter"></i></a>


        </footer>
      </div>
    </div>

    

  </body>
</html>
